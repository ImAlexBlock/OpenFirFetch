# -*- coding: utf-8 -*-
"""
Fir-Fetch (fixed & cleaned)
- æœç´¢ Bingï¼ˆsite:domain + å…³é”®è¯ + filetypeï¼‰
- ä¸‹è½½ pdf/xlsx/html
- æå–èº«ä»½è¯/å­¦å·/è”ç³»æ–¹å¼
- å°†ç–‘ä¼¼æ•æ„Ÿæ–‡ä»¶å½’æ¡£å¹¶ç”ŸæˆåŸŸåçº§æŠ¥å‘Š

ä¸»è¦ä¿®å¤ç‚¹ï¼š
1) ä¿®å¤åç¼–è¯‘å¯¼è‡´çš„é€»è¾‘åè½¬ã€æå‰ returnã€ç¼©è¿›é”™ä¹±ä¸å¼‚å¸¸é“¾ä¸­æ–­
2) å®Œæ•´å®ç°ä¸‹è½½ -> ä¿å­˜ -> å†…å®¹è§£æ -> å½’æ¡£/æŠ¥å‘Š çš„é—­ç¯
3) Playwright æœç´¢æµç¨‹æœ€å°å¯ç”¨å®ç° + åˆ†é¡µ
4) æ›´ç¨³å¥çš„æ­£åˆ™ä¸è¡¨æ ¼è§£æé€»è¾‘ï¼›å‡å°‘è¯¯åˆ¤
5) UIï¼šç›®æ ‡è§£æã€æ—¥å¿—æ˜¾ç¤ºã€ç»“æœç›®å½•æ‰“å¼€ã€å¯å–æ¶ˆçš„æ‰«æçº¿ç¨‹

ä¾èµ–ï¼š
pip install ttkbootstrap pdfplumber playwright httpx pandas lxml openpyxl html5lib
playwright install msedge   # æˆ–ä½¿ç”¨ chromium é»˜è®¤é€šé“

ä½œè€…ï¼šfireflyï¼ˆæœ¬æ–‡ä»¶ä¸ºåœ¨å…¶åŸºç¡€ä¸Šçš„ä¿®å¤ä¸ç²¾ç®€ï¼‰
"""

import asyncio
import hashlib
import logging
import os
import queue
import re
import subprocess
import sys
import threading
import time
from pathlib import Path
from urllib.parse import urlparse

import httpx
import pandas as pd
import pdfplumber
import tkinter as tk
from bs4 import BeautifulSoup
from tkinter import filedialog, messagebox, scrolledtext
import ttkbootstrap as ttk
from ttkbootstrap.constants import *
from playwright.async_api import async_playwright, Error as PlaywrightError

# --------------------------- æ—¥å¿—å™¨ ---------------------------

logger = logging.getLogger(__name__)
if not logger.handlers:
    _h = logging.StreamHandler(sys.stdout)
    _h.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s",
                                      datefmt="%H:%M:%S"))
    logger.addHandler(_h)
logger.setLevel(logging.INFO)

# --------------------------- å…¨å±€é…ç½® ---------------------------

SEARCH_KEYWORDS = ['èº«ä»½è¯', 'å¥–å­¦é‡‘', 'å…¬ç¤º', 'åå•', 'å­¦å·', 'è”ç³»æ–¹å¼']
BLACKLIST = ['è¯¾è¡¨', 'é€‰è¯¾', 'åŸ¹å…»æ–¹æ¡ˆ', 'æ‹›è˜', 'å¼•è¿›', 'è˜ç”¨', 'åº”è˜', 'é¢è¯•', 'é‡‡è´­', 'æ‹›æ ‡',
             'ä¸­æ ‡', 'é¢„ç®—', 'å†³ç®—', 'é¡¹ç›®', 'ä¼šè®®', 'ä¾›åº”å•†', 'æ•™æ', 'ç»Ÿä¸€èº«ä»½è®¤è¯å¹³å°', 'æ™ºæ…§æ ¡å›­', 'ç™»å½•']
TITLE_FILTER_KEYWORDS = ['å¥–å­¦é‡‘', 'åŠ©å­¦é‡‘', 'åå•', 'å…¬ç¤º', 'è¯„å®¡è¡¨', 'æ¯•ä¸šç”Ÿ', 'æ‹Ÿå½•å–', 'è”ç³»', 'é€šè®¯å½•']

SENSITIVE_KEYWORDS = {'å­¦å·', 'èº«ä»½è¯', 'é‚®ç®±', 'æ‰‹æœº'}
GENERAL_KEYWORDS = {'åå•', 'ä¿¡æ¯', 'è¡¨', 'é€šè®¯å½•', 'å…¬ç¤º'}

CHINESE_NAME_REGEX = re.compile(r'[\u4e00-\u9fa5]{2,4}')
ID_LIKE_NUMBER_REGEX = re.compile(r'(?<!\d)(?!\d{11}(?!\d))\d{8,}(?!\d)')

# èº«ä»½è¯å·ç›¸å…³
_ID_CARD_PATTERN = r'[1-9]\d{5}(?:18|19|20)\d{2}(?:0[1-9]|1[0-2])' \
                   r'(?:0[1-9]|[12]\d|3[01])\d{3}[0-9Xx]'
PDF_ID_CARD_CONTEXT_REGEX = re.compile(
    rf'(?:å±…æ°‘èº«ä»½è¯å·|å±…æ°‘èº«ä»½è¯|èº«ä»½è¯å·ç |èº«ä»½è¯å·|èº«ä»½è¯)\s*[:ï¼š]?\s*({_ID_CARD_PATTERN})'
)
ID_CARD_FORMAT_REGEX = re.compile(rf'^{_ID_CARD_PATTERN}$')
ID_LAST6_REGEX = re.compile(r'^\d{5}[\dxX]$')

# å­¦å·
STUDENT_ID_FORMAT_REGEX = re.compile(r'^\d{4,20}$')
PDF_STUDENT_ID_CONTEXT_REGEX = re.compile(r'(?:å­¦å·|å­¦ç”Ÿè¯å·)\s*[:ï¼š]?\s*(\d{4,20})')
PDF_NAME_STUDENT_ID_REGEX = re.compile(r'([\u4e00-\u9fa5]{2,4})\s+(\d{8,20})')

# è”ç³»æ–¹å¼
PHONE_REGEX = re.compile(r'1[3-9]\d{9}')
EMAIL_REGEX = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b')
NAME_PHONE_REGEX = re.compile(r'([\u4e00-\u9fa5]{2,4})\s*[:ï¼š]?\s*(1[3-9]\d{9})')
NAME_EMAIL_REGEX = re.compile(
    r'([\u4e00-\u9fa5]{2,4})\s*[:ï¼š]?\s*([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,})'
)

MIN_FILE_SIZE = 256                 # å­—èŠ‚
MAX_PDF_PAGES = 10
MAX_XLS_SHEETS = 4
HEADER_RANGE = 5

ID_HEADERS = {'èº«ä»½è¯å·', 'èº«ä»½è¯å·ç ', 'èº«ä»½è¯', 'å±…æ°‘èº«ä»½è¯å·', 'å±…æ°‘èº«ä»½è¯'}
STUDENT_ID_HEADERS = {'å­¦å·', 'å­¦ç”Ÿè¯å·'}
PHONE_EMAIL_HEADERS = {'e-mail', 'è”ç³»æ–¹å¼', 'email', 'ç”µè¯', 'æ‰‹æœº', 'é‚®ç®±'}
NAME_HEADERS = {'å§“å', 'è”ç³»äºº'}

MAX_CONCURRENT_TASKS = 25
semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

# è·¨çº¿ç¨‹/åç¨‹å…±äº«
domain_reports: dict[str, list] = {}
report_lock = threading.Lock()
ssl_failed_domains: set[str] = set()

# --------------------------- å·¥å…·å‡½æ•° ---------------------------

def sanitize_name(name: str) -> str:
    return re.sub(r'[\\/*?:"<>|]', '_', name).strip()[:150]


def hash_bytes(data: bytes) -> str:
    return hashlib.md5(data).hexdigest()


def get_filename_from_url(url: str, default_ext: str) -> str:
    path = urlparse(url).path
    base = Path(path).name or "downloaded"
    if '.' not in base and default_ext:
        base += f".{default_ext.lstrip('.')}"
    return sanitize_name(base)


def check_title_is_relevant(title: str) -> bool:
    return any(kw in title for kw in TITLE_FILTER_KEYWORDS)


def check_content_is_relevant(snippet: str) -> bool:
    """ç²—ç•¥ç›¸å…³æ€§ï¼šå«æ•æ„Ÿè¯ + (äººå æˆ– é•¿æ•°å­—)ï¼Œæˆ–å«é€šç”¨è¯ã€‚"""
    snippet = snippet or ""
    contains_sensitive = any(kw in snippet for kw in SENSITIVE_KEYWORDS)
    contains_general = any(kw in snippet for kw in GENERAL_KEYWORDS)
    contains_name = bool(CHINESE_NAME_REGEX.search(snippet))
    contains_long_num = bool(ID_LIKE_NUMBER_REGEX.search(snippet))
    return (contains_sensitive and (contains_name or contains_long_num)) or contains_general


def check_blacklist(title: str, content: str) -> bool:
    t = (title or "") + " " + (content or "")
    t = t.lower()
    return any(word.lower() in t for word in BLACKLIST)


def is_valid_id_full(id_str: str) -> bool:
    return isinstance(id_str, str) and bool(ID_CARD_FORMAT_REGEX.fullmatch(id_str))


def is_valid_id_last6(id_str: str) -> bool:
    return isinstance(id_str, str) and bool(ID_LAST6_REGEX.fullmatch(id_str))


def is_valid_student_id_format(id_str: str) -> bool:
    return isinstance(id_str, str) and bool(STUDENT_ID_FORMAT_REGEX.fullmatch(id_str)) and ('*' not in id_str)


# --------------------------- å†…å®¹æå– ---------------------------

def extract_pdf_ids(file_path: Path, collect_contacts: bool) -> tuple[dict, dict, dict, list[str]]:
    """
    è¿”å›:
      full_ids:    {'ç¬¬Xé¡µ-è¡¨æ ¼'/'ç¬¬Xé¡µ-æ–‡æœ¬': æ¬¡æ•°}
      last6_ids:   åŒä¸Š
      student_ids: åŒä¸Š
      phone_email: å½¢å¦‚ 'å§“å: è”ç³»æ–¹å¼' çš„åˆ—è¡¨ï¼ˆcollect_contacts=True æ—¶ï¼‰
    """
    full_ids, last6_ids, student_ids = {}, {}, {}
    phone_email_results: list[str] = []

    try:
        with pdfplumber.open(file_path) as pdf:
            for page_num, page in enumerate(pdf.pages[:MAX_PDF_PAGES], 1):
                # è¡¨æ ¼
                tables = page.extract_tables() or []
                for table in tables:
                    if not table or len(table) < 2:
                        continue
                    header = [str(c).strip() if c else '' for c in table[0]]

                    id_cols = [i for i, col in enumerate(header) if any(h in col for h in ID_HEADERS)]
                    student_id_cols = [i for i, col in enumerate(header) if any(h in col for h in STUDENT_ID_HEADERS)]
                    name_cols = [i for i, col in enumerate(header) if any(h in col for h in NAME_HEADERS)]
                    pe_cols = [i for i, col in enumerate(header) if any(h in col for h in PHONE_EMAIL_HEADERS)]

                    # èº«ä»½è¯åˆ—
                    for col_idx in id_cols:
                        for row in table[1:]:
                            if len(row) <= col_idx:
                                continue
                            cell = str(row[col_idx] or '').strip().split('.')[0]
                            if not cell:
                                continue
                            if is_valid_id_full(cell):
                                key = f'ç¬¬{page_num}é¡µ-è¡¨æ ¼'
                                full_ids[key] = full_ids.get(key, 0) + 1
                            elif len(cell) >= 6 and is_valid_id_last6(cell[-6:].upper()):
                                key = f'ç¬¬{page_num}é¡µ-è¡¨æ ¼'
                                last6_ids[key] = last6_ids.get(key, 0) + 1

                    # å­¦å·åˆ—
                    for col_idx in student_id_cols:
                        for row in table[1:]:
                            if len(row) <= col_idx:
                                continue
                            cell = str(row[col_idx] or '').strip().split('.')[0]
                            if not cell:
                                continue
                            if is_valid_student_id_format(cell):
                                key = f'ç¬¬{page_num}é¡µ-è¡¨æ ¼'
                                student_ids[key] = student_ids.get(key, 0) + 1

                    # è”ç³»æ–¹å¼åˆ—
                    if collect_contacts and name_cols and pe_cols:
                        name_col = name_cols[0]
                        for pe_col in pe_cols:
                            for row in table[1:]:
                                if len(row) <= max(name_col, pe_col):
                                    continue
                                name = str(row[name_col] or '').strip()
                                contact_info = str(row[pe_col] or '').strip()
                                if not name or not contact_info:
                                    continue
                                if PHONE_REGEX.search(contact_info) or EMAIL_REGEX.search(contact_info):
                                    phone_email_results.append(f'{name}: {contact_info}')

                # æ–‡æœ¬
                text = page.extract_text() or ''
                for m in PDF_ID_CARD_CONTEXT_REGEX.finditer(text):
                    if is_valid_id_full(m.group(1)):
                        key = f'ç¬¬{page_num}é¡µ-æ–‡æœ¬'
                        full_ids[key] = full_ids.get(key, 0) + 1
                for m in PDF_STUDENT_ID_CONTEXT_REGEX.finditer(text):
                    if is_valid_student_id_format(m.group(1)):
                        key = f'ç¬¬{page_num}é¡µ-æ–‡æœ¬'
                        student_ids[key] = student_ids.get(key, 0) + 1
                for m in PDF_NAME_STUDENT_ID_REGEX.finditer(text):
                    if is_valid_student_id_format(m.group(2)):
                        key = f'ç¬¬{page_num}é¡µ-æ–‡æœ¬(å§“å+å­¦å·)'
                        student_ids[key] = student_ids.get(key, 0) + 1

                if collect_contacts:
                    for m in NAME_PHONE_REGEX.finditer(text):
                        phone_email_results.append(f'{m.group(1)}: {m.group(2)}')
                    for m in NAME_EMAIL_REGEX.finditer(text):
                        phone_email_results.append(f'{m.group(1)}: {m.group(2)}')
                    for phone in PHONE_REGEX.findall(text):
                        phone_email_results.append(f'å•ç‹¬æ‰‹æœºå·: {phone}')
                    for email in EMAIL_REGEX.findall(text):
                        phone_email_results.append(f'å•ç‹¬é‚®ç®±: {email}')

        return full_ids, last6_ids, student_ids, phone_email_results
    except Exception as e:
        logger.error(f'PDF è§£æå¤±è´¥: {file_path.name} - {e}')
        return full_ids, last6_ids, student_ids, phone_email_results


def extract_xlsx_ids(file_path: Path, collect_contacts: bool) -> tuple[dict, dict, dict, list[str]]:
    full_ids, last6_ids, student_ids = {}, {}, {}
    phone_email_results: list[str] = []

    try:
        with pd.ExcelFile(file_path) as xls:
            for sheet_name in xls.sheet_names[:MAX_XLS_SHEETS]:
                df = pd.read_excel(xls, sheet_name=sheet_name, header=None)
                if df.empty:
                    continue

                # ç²—æ‰«ï¼šéå†å•å…ƒæ ¼ï¼ˆæ¯”çŒœè¡¨å¤´æ›´é²æ£’ï¼‰
                for _, row in df.iterrows():
                    for cell in row.tolist():
                        s = str(cell or '').strip()
                        if not s:
                            continue
                        # èº«ä»½è¯
                        if is_valid_id_full(s):
                            full_ids[sheet_name] = full_ids.get(sheet_name, 0) + 1
                        elif len(s) >= 6 and is_valid_id_last6(s[-6:].upper()):
                            last6_ids[sheet_name] = last6_ids.get(sheet_name, 0) + 1
                        # å­¦å·
                        if is_valid_student_id_format(s):
                            student_ids[sheet_name] = student_ids.get(sheet_name, 0) + 1
                        # è”ç³»æ–¹å¼
                        if collect_contacts:
                            if PHONE_REGEX.search(s):
                                phone_email_results.append(f'å•ç‹¬æ‰‹æœºå·: {PHONE_REGEX.search(s).group(0)}')
                            for em in EMAIL_REGEX.findall(s):
                                phone_email_results.append(f'å•ç‹¬é‚®ç®±: {em}')

        return full_ids, last6_ids, student_ids, phone_email_results
    except Exception as e:
        logger.error(f'Excel è§£æå¤±è´¥: {file_path.name} - {e}')
        return full_ids, last6_ids, student_ids, phone_email_results


def extract_html_ids(file_path: Path, collect_contacts: bool) -> tuple[dict, dict, dict, list[str]]:
    full_ids, last6_ids, student_ids = {}, {}, {}
    phone_email_results: list[str] = []

    try:
        # å…ˆå°è¯•è¡¨æ ¼
        try:
            dfs = pd.read_html(str(file_path), encoding='utf-8', flavor='html5lib')
        except ValueError:
            dfs = []

        for i, df in enumerate(dfs):
            if df.empty:
                continue
            sheet_name = f'è¡¨æ ¼-{i + 1}'
            for _, row in df.iterrows():
                for cell in row.tolist():
                    s = str(cell or '').strip()
                    if not s:
                        continue
                    if is_valid_id_full(s):
                        full_ids[sheet_name] = full_ids.get(sheet_name, 0) + 1
                    elif len(s) >= 6 and is_valid_id_last6(s[-6:].upper()):
                        last6_ids[sheet_name] = last6_ids.get(sheet_name, 0) + 1
                    if is_valid_student_id_format(s):
                        student_ids[sheet_name] = student_ids.get(sheet_name, 0) + 1
                    if collect_contacts:
                        if PHONE_REGEX.search(s):
                            phone_email_results.append(f'å•ç‹¬æ‰‹æœºå·: {PHONE_REGEX.search(s).group(0)}')
                        for em in EMAIL_REGEX.findall(s):
                            phone_email_results.append(f'å•ç‹¬é‚®ç®±: {em}')

        # å†è§£æå…¨æ–‡æ–‡æœ¬
        html_content = file_path.read_text(encoding='utf-8', errors='ignore')
        soup = BeautifulSoup(html_content, 'lxml')
        text = soup.get_text(separator=' ') if soup else html_content

        for m in PDF_ID_CARD_CONTEXT_REGEX.finditer(text):
            if is_valid_id_full(m.group(1)):
                full_ids['é¡µé¢æ–‡æœ¬'] = full_ids.get('é¡µé¢æ–‡æœ¬', 0) + 1
        for m in PDF_STUDENT_ID_CONTEXT_REGEX.finditer(text):
            if is_valid_student_id_format(m.group(1)):
                student_ids['é¡µé¢æ–‡æœ¬'] = student_ids.get('é¡µé¢æ–‡æœ¬', 0) + 1

        for name, sid in PDF_NAME_STUDENT_ID_REGEX.findall(text):
            if is_valid_student_id_format(sid):
                student_ids['é¡µé¢æ–‡æœ¬(å§“å+å­¦å·)'] = student_ids.get('é¡µé¢æ–‡æœ¬(å§“å+å­¦å·)', 0) + 1

        if collect_contacts:
            for m in NAME_PHONE_REGEX.finditer(text):
                phone_email_results.append(f'{m.group(1)}: {m.group(2)}')
            for m in NAME_EMAIL_REGEX.finditer(text):
                phone_email_results.append(f'{m.group(1)}: {m.group(2)}')
            for phone in PHONE_REGEX.findall(text):
                phone_email_results.append(f'å•ç‹¬æ‰‹æœºå·: {phone}')
            for email in EMAIL_REGEX.findall(text):
                phone_email_results.append(f'å•ç‹¬é‚®ç®±: {email}')

        return full_ids, last6_ids, student_ids, phone_email_results
    except Exception as e:
        logger.error(f'HTML è§£æå¤±è´¥: {file_path.name} - {e}')
        return full_ids, last6_ids, student_ids, phone_email_results


# --------------------------- ä¸‹è½½ä¸å½’æ¡£ ---------------------------

async def download_and_analyze(
    url: str,
    title: str,
    domain: str,
    download_dir: Path,
    id_card_dir: Path,
    student_id_dir: Path,
    phone_email_dir: Path,
    file_counter_state: dict,
    processed_phone_email: set[str],
    processed_content_hashes: set[str],
    collect_contacts: bool,
    expected_ext: str | None = None,
) -> None:
    """ä¸‹è½½ URLï¼Œä¿å­˜å¹¶è§£æã€‚æ ¹æ®ç»“æœå°†æ•æ„Ÿæ–‡ä»¶ç§»åŠ¨åˆ°å¯¹åº”ç›®å½•ï¼Œå¹¶è®°å½•æŠ¥å‘Šã€‚"""
    async with semaphore:
        parsed_url = urlparse(url)
        headers = {
            'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                           'AppleWebKit/537.36 (KHTML, like Gecko) '
                           'Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'),
            'Accept': ('text/html,application/xhtml+xml,application/xml;'
                       'q=0.9,image/webp,image/apng,*/*;q=0.8,'
                       'application/signed-exchange;v=b3;q=0.7'),
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': f'{parsed_url.scheme}://{parsed_url.netloc}/',
        }

        with report_lock:
            verify_param = domain not in ssl_failed_domains

        content = None
        last_exc = None

        for attempt in range(2):
            try:
                async with httpx.AsyncClient(verify=verify_param, follow_redirects=True, timeout=30) as client:
                    resp = await client.get(url, headers=headers)
                    resp.raise_for_status()
                    content = resp.content
                    break
            except httpx.ConnectError as e:
                if 'CERTIFICATE_VERIFY_FAILED' in str(e) and verify_param:
                    logger.warning(f'ğŸš¨ åŸŸå \'{domain}\' é¦–æ¬¡ SSL éªŒè¯å¤±è´¥ï¼Œå°†åœ¨åç»­è¯·æ±‚ç¦ç”¨éªŒè¯ã€‚')
                    with report_lock:
                        ssl_failed_domains.add(domain)
                    verify_param = False
                    last_exc = e
                    continue
                last_exc = e
                break
            except httpx.HTTPStatusError as e:
                last_exc = e
                break
            except Exception as e:
                last_exc = e
                break

        if content is None:
            logger.error(f'ä¸‹è½½å¤±è´¥: {url} - {last_exc}')
            return

        if len(content) < MIN_FILE_SIZE:
            logger.debug(f'å¿½ç•¥è¿‡å°æ–‡ä»¶ ({len(content)} B): {url}')
            return

        # å»é‡
        h = hash_bytes(content)
        if h in processed_content_hashes:
            logger.debug(f'é‡å¤å†…å®¹ï¼Œè·³è¿‡: {url}')
            return
        processed_content_hashes.add(h)

        # ä¿å­˜
        ext = (expected_ext or '').lower().lstrip('.')
        if not ext:
            # ä»è·¯å¾„çŒœæ‰©å±•
            guess = Path(urlparse(url).path).suffix.lower().lstrip('.')
            ext = guess or 'html'
        fname_base = f"{file_counter_state['count']:04d} - {sanitize_name(title or get_filename_from_url(url, ext))}"
        fname = f"{fname_base}.{ext}" if not fname_base.lower().endswith(f".{ext}") else fname_base
        file_counter_state['count'] += 1

        save_path = download_dir / fname
        try:
            save_path.write_bytes(content)
        except Exception as e:
            logger.error(f'ä¿å­˜å¤±è´¥: {save_path.name} - {e}')
            return

        # è§£æ
        full_ids, last6_ids, student_ids, phone_emails = {}, {}, {}, []
        try:
            if ext == 'pdf':
                full_ids, last6_ids, student_ids, phone_emails = extract_pdf_ids(save_path, collect_contacts)
            elif ext in ('xlsx', 'xls'):
                full_ids, last6_ids, student_ids, phone_emails = extract_xlsx_ids(save_path, collect_contacts)
            else:
                # é»˜è®¤å½“ä½œ html
                full_ids, last6_ids, student_ids, phone_emails = extract_html_ids(save_path, collect_contacts)
        except Exception as e:
            logger.error(f'è§£æå¤±è´¥: {save_path.name} - {e}')

        # è”ç³»æ–¹å¼åˆå¹¶å»é‡
        if collect_contacts and phone_emails:
            with report_lock:
                processed_phone_email.update(phone_emails)

        # æ•æ„Ÿå½’æ¡£ + æŠ¥å‘Š
        def _move_unique(dst_dir: Path, path: Path) -> Path:
            dst = dst_dir / path.name
            if dst.exists():
                dst = dst_dir / f"{path.stem}_{int(time.time())}{path.suffix}"
            try:
                path.replace(dst)
                return dst
            except Exception as move_e:
                logger.error(f'ç§»åŠ¨æ•æ„Ÿæ–‡ä»¶å¤±è´¥: {path.name} -> {dst_dir} - {move_e}')
                return path

        def _append_report(_type: str, details: str):
            with report_lock:
                domain_reports.setdefault(domain, []).append({
                    'file': save_path.name,
                    'title': title,
                    'url': url,
                    'type': _type,
                    'details': details
                })

        # èº«ä»½è¯
        if full_ids or last6_ids:
            parts = []
            if full_ids:
                parts.append("å®Œæ•´èº«ä»½è¯å·: " + "; ".join(f"{k}:{v}" for k, v in full_ids.items()))
            if last6_ids:
                parts.append("èº«ä»½è¯å6ä½: " + "; ".join(f"{k}:{v}" for k, v in last6_ids.items()))
            details = "; ".join(parts) if parts else "ç–‘ä¼¼èº«ä»½è¯ä¿¡æ¯"
            logger.warning(f'ğŸš¨ æ•æ„Ÿæ–‡ä»¶(èº«ä»½è¯) [{domain}]: {save_path.name} â†’ {details}')
            _append_report('èº«ä»½è¯', details)
            _ = _move_unique(id_card_dir, save_path)
            return

        # å­¦å·
        if student_ids:
            details = "å­¦å·: " + "; ".join(f"{k}:{v}" for k, v in student_ids.items())
            logger.warning(f'ğŸš¨ æ•æ„Ÿæ–‡ä»¶(å­¦å·) [{domain}]: {save_path.name} â†’ {details}')
            _append_report('å­¦å·', details)
            _ = _move_unique(student_id_dir, save_path)
            return

        # ä»…è”ç³»æ–¹å¼ï¼ˆå¯é€‰ï¼‰
        if collect_contacts and processed_phone_email:
            # ä¸ºäº†é¿å…å¤§é‡é‡å¤ï¼Œåªè®°å½•ä¸€æ¬¡â€œæ‰‹æœºå·å’Œé‚®ç®±â€
            _append_report('æ‰‹æœºå·å’Œé‚®ç®±', f'ç´¯è®¡ {len(processed_phone_email)} æ¡ï¼ˆå»é‡åï¼‰')
            # ç§»åŠ¨æ–‡ä»¶åˆ°ç›®å½•ï¼ˆéå¿…é¡»ï¼‰
            _ = _move_unique(phone_email_dir, save_path)
            return

        # éæ•æ„Ÿä¿ç•™åœ¨ä¸‹è½½ç›®å½•
        logger.info(f'å·²è§£æï¼ˆæ— æ•æ„Ÿå‘½ä¸­ï¼‰: {save_path.name}')


# --------------------------- æœç´¢ä¸æŠ“å– ---------------------------

async def extract_results_from_page(page):
    """è§£æ Bing æœç´¢ç»“æœï¼Œè¿”å› [(title, url, snippet)]"""
    results = []
    try:
        await page.wait_for_selector('li.b_algo h2 a', timeout=15000)
        items = await page.locator('li.b_algo').all()
        for it in items:
            try:
                a = it.locator('h2 a')
                title = (await a.text_content()) or ''
                url = await a.get_attribute('href')
                snippet = await it.locator('.b_caption p').text_content() if await it.locator('.b_caption p').count() else ''
                if url:
                    results.append((title.strip(), url.strip(), (snippet or '').strip()))
            except Exception:
                continue
    except PlaywrightError:
        logger.info('é¡µé¢ä¸Šæœªæ‰¾åˆ°ä»»ä½•ç»“æœ (b_algo)ã€‚å¯èƒ½å‡ºç°äººæœºéªŒè¯æˆ–æ— ç»“æœã€‚')
    return results


async def search_worker(
    context,
    file_type: str,                  # 'pdf' / 'xlsx' / 'html'
    domain: str,
    pages: int,
    download_dir: Path,
    id_card_dir: Path,
    student_id_dir: Path,
    phone_email_dir: Path,
    file_counter_state: dict,
    processed_urls: set[str],
    processed_phone_email: set[str],
    processed_content_hashes: set[str],
    collect_contacts: bool,
    search_keywords: list[str],
):
    page = await context.new_page()
    # å±è”½å›¾ç‰‡/æ ·å¼ç­‰
    await page.route('**/*', lambda route: route.abort()
                     if route.request.resource_type not in ['document', 'script', 'xhr', 'fetch']
                     else route.continue_())

    try:
        await page.goto('https://www.bing.com', wait_until='domcontentloaded', timeout=30000)

        # é€å…³é”®è¯æ£€ç´¢
        for kw in search_keywords:
            # Bing æ”¯æŒ filetype:pdf / filetype:xlsxï¼›html ä¸åŠ  filetype
            if file_type in ('pdf', 'xlsx'):
                query = f'site:{domain} {kw} filetype:{file_type}'
                expected_ext = file_type
            else:
                query = f'site:{domain} {kw}'
                expected_ext = None

            logger.info(f'ğŸ” [{domain}] æœç´¢: {query}')
            sb = page.locator('#sb_form_q')
            await sb.fill(query)
            await sb.press('Enter')
            await page.wait_for_load_state('domcontentloaded')

            for p in range(pages):
                results = await extract_results_from_page(page)
                if not results:
                    break

                for title, url, snippet in results:
                    if domain not in url:
                        continue
                    if check_blacklist(title, snippet):
                        continue
                    # å¯¹ htmlï¼Œä¼˜å…ˆè¦æ±‚æ ‡é¢˜ç›¸å…³æ€§ï¼›å¯¹æ–‡æ¡£ç±»å‹æ”¾å®½
                    if file_type == 'html' and (not check_title_is_relevant(title)) and (not check_content_is_relevant(snippet)):
                        continue

                    if url in processed_urls:
                        continue
                    processed_urls.add(url)

                    # å¯åŠ¨ä¸‹è½½ä»»åŠ¡
                    await download_and_analyze(
                        url=url,
                        title=title,
                        domain=domain,
                        download_dir=download_dir,
                        id_card_dir=id_card_dir,
                        student_id_dir=student_id_dir,
                        phone_email_dir=phone_email_dir,
                        file_counter_state=file_counter_state,
                        processed_phone_email=processed_phone_email,
                        processed_content_hashes=processed_content_hashes,
                        collect_contacts=collect_contacts,
                        expected_ext=expected_ext,
                    )

                # ä¸‹ä¸€é¡µ
                try:
                    # é€‚é…å¤šç§åˆ†é¡µé€‰æ‹©å™¨
                    if await page.locator('a.sb_pagN').count():
                        await page.locator('a.sb_pagN').first.click()
                    elif await page.locator('a[title="Next page"]').count():
                        await page.locator('a[title="Next page"]').first.click()
                    else:
                        break
                    await page.wait_for_load_state('domcontentloaded')
                except Exception:
                    break

    except Exception as e:
        logger.error(f'æœç´¢ä»»åŠ¡å¤±è´¥ (ç±»å‹: {file_type}): {e}')
    finally:
        await page.close()


async def scan_domain(browser, domain: str, pages: int, show_browser: bool, proxy: str, collect_contacts: bool):
    logger.info(f"\n==================== å¼€å§‹æ‰«æåŸŸå: {domain} ====================")

    base_dir = Path(__file__).parent.resolve() / 'data'
    download_dir = base_dir / 'downloads' / domain
    sensitive_base_dir = base_dir / 'sensitive_files' / domain
    id_card_dir = sensitive_base_dir / 'èº«ä»½è¯'
    student_id_dir = sensitive_base_dir / 'å­¦å·'
    phone_email_dir = sensitive_base_dir / 'æ‰‹æœºå·å’Œé‚®ç®±'
    for d in (download_dir, id_card_dir, student_id_dir, phone_email_dir):
        d.mkdir(parents=True, exist_ok=True)

    with report_lock:
        domain_reports[domain] = []

    processed_urls: set[str] = set()
    processed_content_hashes: set[str] = set()
    processed_phone_email: set[str] = set()

    file_counter_state = {'count': 1}
    current_search_keywords = list(SEARCH_KEYWORDS)

    if not collect_contacts and 'è”ç³»æ–¹å¼' in current_search_keywords:
        current_search_keywords.remove('è”ç³»æ–¹å¼')
        logger.info('â„¹ï¸ å·²ç¦ç”¨è”ç³»æ–¹å¼æ”¶é›†ï¼Œå°†è·³è¿‡ç›¸å…³å…³é”®å­—ã€‚')

    try:
        context = await browser.new_context(
            user_agent=('Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                        'AppleWebKit/537.36 (KHTML, like Gecko) '
                        'Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'),
            java_script_enabled=True,
        )

        tasks = [
            search_worker(context, 'pdf', domain, pages, download_dir, id_card_dir, student_id_dir,
                          phone_email_dir, file_counter_state, processed_urls, processed_phone_email,
                          processed_content_hashes, collect_contacts, current_search_keywords),
            search_worker(context, 'xlsx', domain, pages, download_dir, id_card_dir, student_id_dir,
                          phone_email_dir, file_counter_state, processed_urls, processed_phone_email,
                          processed_content_hashes, collect_contacts, current_search_keywords),
            search_worker(context, 'html', domain, pages, download_dir, id_card_dir, student_id_dir,
                          phone_email_dir, file_counter_state, processed_urls, processed_phone_email,
                          processed_content_hashes, collect_contacts, current_search_keywords),
        ]
        await asyncio.gather(*tasks)
        await context.close()
    except PlaywrightError as e:
        logger.critical(f'æµè§ˆå™¨æ“ä½œå¤±è´¥ [{domain}]: {e}')


def print_final_report():
    logger.info("\n========================= æ‰«æå®Œæˆ - æ£€æµ‹æŠ¥å‘Š =========================")
    found_any = False

    for domain, report in domain_reports.items():
        if not report:
            logger.info(f'\nâœ… åŸŸå: {domain} â†’ æœªå‘ç°æ•æ„Ÿæ–‡ä»¶ï¼')
            continue

        found_any = True
        logger.warning(f'\nğŸš¨ åŸŸå: {domain} â†’ å‘ç° {len(report)} ä¸ªæ•æ„Ÿæ–‡ä»¶/è®°å½•:')

        # å°è¯•æŒ‰æ–‡ä»¶å‰ç¼€ç¼–å·æ’åº
        try:
            sorted_report = sorted(report, key=lambda x: int((x["file"].split(" - ")[0]).lstrip("0") or "0"))
        except Exception:
            sorted_report = report

        phone_email_reported = False
        for i, item in enumerate(sorted_report, 1):
            if item['type'] == 'æ‰‹æœºå·å’Œé‚®ç®±' and phone_email_reported:
                # é¿å…é‡å¤åˆ·å±
                continue

            log_message = (
                f"\n  --- [{i}] æ–‡ä»¶å/æ¥æº: {item['file']}"
                f"\n      ç±»å‹: {item['type']}"
                f"\n      æ ‡é¢˜: {item['title']}"
                f"\n      URL: {item['url']}"
                f"\n      è¯¦æƒ…: {item['details']}"
            )
            logger.warning(log_message)

            if item['type'] == 'æ‰‹æœºå·å’Œé‚®ç®±':
                phone_email_reported = True

    if not found_any:
        logger.info('\nğŸ‰ æœªå‘ç°ä»»ä½•æ•æ„Ÿæ–‡ä»¶ï¼')


async def async_main_logic(target_domains, pages, show_browser, proxy, collect_contacts):
    async with async_playwright() as p:
        browser_opts = {'headless': not show_browser, 'args': ['--no-sandbox', '--disable-gpu']}
        if proxy:
            browser_opts['proxy'] = {'server': proxy}

        logger.info('æ­£åœ¨å¯åŠ¨ Edge/Chromium æµè§ˆå™¨...')
        try:
            # ä¼˜å…ˆä½¿ç”¨ Edge é€šé“ï¼›å¤±è´¥åˆ™é€€å›é»˜è®¤ Chromium
            try:
                browser = await p.chromium.launch(channel='msedge', **browser_opts)
            except PlaywrightError:
                browser = await p.chromium.launch(**browser_opts)

            logger.info(f'å¼€å§‹æ‰«æï¼ˆæ¯ä¸ªå…³é”®è¯æœ€å¤šæ‰«æ {pages} é¡µï¼‰...')
            for domain in target_domains:
                await asyncio.sleep(0)
                await scan_domain(browser, domain, pages, show_browser, proxy, collect_contacts)

            await browser.close()
            logger.info('æµè§ˆå™¨å·²å…³é—­')
            print_final_report()
        except PlaywrightError:
            logger.critical('æµè§ˆå™¨å¯åŠ¨å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é¦–æ¬¡å®‰è£…ã€‚')
            logger.info('å°è¯•è‡ªåŠ¨å®‰è£…æµè§ˆå™¨ä¾èµ–...')
            try:
                subprocess.run([sys.executable, '-m', 'playwright', 'install', 'msedge'],
                               check=True, capture_output=True, text=True, encoding='utf-8')
                subprocess.run([sys.executable, '-m', 'playwright', 'install-deps', 'msedge'],
                               check=True, capture_output=True, text=True, encoding='utf-8')
                logger.info('ä¾èµ–å®‰è£…æˆåŠŸï¼è¯·é‡æ–°å¯åŠ¨ç¨‹åºå¹¶å¼€å§‹æ‰«æã€‚')
            except subprocess.CalledProcessError as e:
                logger.critical(f'è‡ªåŠ¨å®‰è£…å¤±è´¥: {e}\nOutput: {e.stdout}\nError: {e.stderr}')
                logger.info("å¯æ‰‹åŠ¨æ‰§è¡Œï¼š'playwright install msedge' ä¸ 'playwright install-deps msedge'")


# --------------------------- GUI æ—¥å¿—é˜Ÿåˆ— ---------------------------

class QueueHandler(logging.Handler):
    def __init__(self, log_queue: queue.Queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record):
        self.log_queue.put(self.format(record))


# --------------------------- è®¾ç½®çª—å£ ---------------------------

class SettingsWindow(tk.Toplevel):
    def __init__(self, parent):
        super().__init__(parent)
        self.title('è®¾ç½®')
        self.transient(parent)
        self.grab_set()
        self.bg_color = parent.style.colors.get('bg')
        self.configure(bg=self.bg_color)
        self.create_widgets()
        self.center_window()

    def center_window(self):
        self.update_idletasks()
        width, height = 700, 600
        parent = self.master
        x = parent.winfo_x() + parent.winfo_width() // 2 - width // 2
        y = parent.winfo_y() + parent.winfo_height() // 2 - height // 2
        self.geometry(f'{width}x{height}+{x}+{y}')

    def create_widgets(self):
        main = ttk.Frame(self, padding=10)
        main.pack(fill=BOTH, expand=True)

        notebook = ttk.Notebook(main)
        notebook.pack(fill=BOTH, expand=True, pady=(0, 10))

        # æœç´¢å…³é”®è¯
        tab_search = ttk.Frame(notebook, padding=10)
        notebook.add(tab_search, text='æœç´¢å…³é”®è¯')
        ttk.Label(tab_search, text='æœç´¢å…³é”®è¯ (æ¯è¡Œä¸€ä¸ª):', style='White.TLabel').pack(fill=X, pady=(5, 5), anchor='w')
        self.search_keywords_text = scrolledtext.ScrolledText(tab_search, height=15, relief='solid', borderwidth=1,
                                                              font=('Microsoft YaHei UI', 10),
                                                              background='#2C3E50', foreground='white',
                                                              insertbackground='white')
        self.search_keywords_text.pack(fill=BOTH, expand=True)
        self.search_keywords_text.insert(tk.END, '\n'.join(SEARCH_KEYWORDS))

        # æ ‡é¢˜é»‘åå•
        tab_blacklist = ttk.Frame(notebook, padding=10)
        notebook.add(tab_blacklist, text='æ ‡é¢˜é»‘åå•')
        ttk.Label(tab_blacklist, text='URL/æ ‡é¢˜é»‘åå•å…³é”®è¯ (æ¯è¡Œä¸€ä¸ª):', style='White.TLabel')\
            .pack(fill=X, pady=(5, 5), anchor='w')
        self.blacklist_text = scrolledtext.ScrolledText(tab_blacklist, height=15, relief='solid', borderwidth=1,
                                                        font=('Microsoft YaHei UI', 10),
                                                        background='#2C3E50', foreground='white',
                                                        insertbackground='white')
        self.blacklist_text.pack(fill=BOTH, expand=True)
        self.blacklist_text.insert(tk.END, '\n'.join(BLACKLIST))

        # æ ‡é¢˜ç™½åå•
        tab_title_whitelist = ttk.Frame(notebook, padding=10)
        notebook.add(tab_title_whitelist, text='æ ‡é¢˜ç™½åå•')
        ttk.Label(tab_title_whitelist, text='æ ‡é¢˜ç™½åå•å…³é”®è¯ (æ¯è¡Œä¸€ä¸ª):', style='White.TLabel')\
            .pack(fill=X, pady=(5, 5), anchor='w')
        self.title_filter_text = scrolledtext.ScrolledText(tab_title_whitelist, height=15, relief='solid',
                                                           borderwidth=1, font=('Microsoft YaHei UI', 10),
                                                           background='#2C3E50', foreground='white',
                                                           insertbackground='white')
        self.title_filter_text.pack(fill=BOTH, expand=True)
        self.title_filter_text.insert(tk.END, '\n'.join(TITLE_FILTER_KEYWORDS))

        # å†…å®¹æ£€æµ‹å…³é”®å­—
        tab_content_keywords = ttk.Frame(notebook, padding=10)
        tab_content_keywords.columnconfigure(0, weight=1)
        tab_content_keywords.rowconfigure(1, weight=1)
        tab_content_keywords.rowconfigure(3, weight=1)
        notebook.add(tab_content_keywords, text='å†…å®¹æ£€æµ‹å…³é”®å­—')

        ttk.Label(tab_content_keywords, text='å†…å®¹æ•æ„Ÿå…³é”®è¯ (æ¯è¡Œä¸€ä¸ª):', style='White.TLabel')\
            .grid(row=0, column=0, sticky='w', pady=(5, 5))
        self.sensitive_keywords_text = scrolledtext.ScrolledText(tab_content_keywords, height=6, relief='solid',
                                                                 borderwidth=1, font=('Microsoft YaHei UI', 10),
                                                                 background='#2C3E50', foreground='white',
                                                                 insertbackground='white')
        self.sensitive_keywords_text.grid(row=1, column=0, sticky='nsew')
        self.sensitive_keywords_text.insert(tk.END, '\n'.join(SENSITIVE_KEYWORDS))

        ttk.Label(tab_content_keywords, text='å†…å®¹é€šç”¨å…³é”®è¯ (æ¯è¡Œä¸€ä¸ª):', style='White.TLabel')\
            .grid(row=2, column=0, sticky='w', pady=(15, 5))
        self.general_keywords_text = scrolledtext.ScrolledText(tab_content_keywords, height=6, relief='solid',
                                                               borderwidth=1, font=('Microsoft YaHei UI', 10),
                                                               background='#2C3E50', foreground='white',
                                                               insertbackground='white')
        self.general_keywords_text.grid(row=3, column=0, sticky='nsew')
        self.general_keywords_text.insert(tk.END, '\n'.join(GENERAL_KEYWORDS))

        # æŒ‰é’®
        btn_frame = ttk.Frame(main)
        btn_frame.pack(side=BOTTOM, fill=X, pady=(10, 0))
        ttk.Button(btn_frame, text='ä¿å­˜', command=self.save_settings, bootstyle='success').pack(side=RIGHT)
        ttk.Button(btn_frame, text='å–æ¶ˆ', command=self.destroy, bootstyle='secondary-outline').pack(side=RIGHT, padx=5)

    def save_settings(self):
        global SEARCH_KEYWORDS, BLACKLIST, TITLE_FILTER_KEYWORDS, SENSITIVE_KEYWORDS, GENERAL_KEYWORDS
        SEARCH_KEYWORDS = [line.strip() for line in self.search_keywords_text.get('1.0', tk.END).splitlines() if line.strip()]
        BLACKLIST = [line.strip() for line in self.blacklist_text.get('1.0', tk.END).splitlines() if line.strip()]
        TITLE_FILTER_KEYWORDS = [line.strip() for line in self.title_filter_text.get('1.0', tk.END).splitlines() if line.strip()]
        SENSITIVE_KEYWORDS = {line.strip() for line in self.sensitive_keywords_text.get('1.0', tk.END).splitlines() if line.strip()}
        GENERAL_KEYWORDS = {line.strip() for line in self.general_keywords_text.get('1.0', tk.END).splitlines() if line.strip()}
        messagebox.showinfo('æˆåŠŸ', 'è®¾ç½®å·²ä¿å­˜ã€‚', parent=self)
        self.destroy()


# --------------------------- UI ç»„ä»¶ ---------------------------

class GradientFrame(tk.Canvas):
    def __init__(self, parent, colors=('gray20', 'gray10'), **kwargs):
        tk.Canvas.__init__(self, parent, **kwargs)
        self.colors = colors
        self.bind('<Configure>', self.draw_gradient)

    def draw_gradient(self, event=None):
        self.delete('gradient')
        width = self.winfo_width()
        height = self.winfo_height()
        r1, g1, b1 = self.winfo_rgb(self.colors[0])
        r2, g2, b2 = self.winfo_rgb(self.colors[1])
        r_ratio = float(r2 - r1) / max(height, 1)
        g_ratio = float(g2 - g1) / max(height, 1)
        b_ratio = float(b2 - b1) / max(height, 1)
        for i in range(height):
            nr = int(r1 + r_ratio * i)
            ng = int(g1 + g_ratio * i)
            nb = int(b1 + b_ratio * i)
            color = f'#{nr // 256:02x}{ng // 256:02x}{nb // 256:02x}'
            self.create_line(0, i, width, i, tags=('gradient',), fill=color)


class App(ttk.Window):
    def __init__(self, themename='darkly'):
        super().__init__(themename=themename)
        self.title('Fir-Fetch Plus')
        self.geometry('960x600')

        self.bg_color = self.style.colors.get('bg')
        self.style.configure('Transparent.TFrame', background=self.bg_color)
        self.style.configure('White.TLabel', foreground=self.style.colors.get('fg'), background=self.bg_color,
                             font=('Microsoft YaHei UI', 10))
        self.style.configure('White.TLabelframe.Label', foreground=self.style.colors.get('fg'), background=self.bg_color,
                             font=('Microsoft YaHei UI', 10))

        self.placeholder_text = 'è¾“å…¥å•ä¸ªåŸŸåæˆ–æµè§ˆæ–‡ä»¶...'
        self.placeholder_color = 'grey'
        self.default_fg_color = self.style.lookup('TEntry', 'foreground')

        self.create_widgets()
        self.setup_logging()

        self.scan_thread: threading.Thread | None = None
        self.scan_loop: asyncio.AbstractEventLoop | None = None

    # ----- UI æ„å»º -----
    def create_widgets(self):
        bg_frame = GradientFrame(self, colors=('#2E3B55', '#1C2833'))
        bg_frame.pack(fill=BOTH, expand=True)

        main_frame = ttk.Frame(bg_frame, padding='15', style='Transparent.TFrame')
        main_frame.pack(fill=BOTH, expand=True)
        main_frame.grid_rowconfigure(1, weight=1)
        main_frame.grid_columnconfigure(0, weight=1)

        controls = ttk.Labelframe(main_frame, text='æ‰«æé…ç½®', padding='10', style='White.TLabelframe')
        controls.grid(row=0, column=0, sticky='ew', pady=(0, 10))
        controls.grid_columnconfigure(1, weight=1)

        ttk.Label(controls, text='ç›®æ ‡:', style='White.TLabel').grid(row=0, column=0, sticky='w', padx=5, pady=5)
        self.target_var = tk.StringVar()
        self.target_entry = ttk.Entry(controls, textvariable=self.target_var, font=('Microsoft YaHei UI', 10))
        self.target_entry.grid(row=0, column=1, sticky='ew', padx=(0, 5), pady=5)
        self.target_entry.insert(0, self.placeholder_text)
        self.target_entry.config(foreground=self.placeholder_color)
        self.target_entry.bind('<FocusIn>', self.on_target_focus_in)
        self.target_entry.bind('<FocusOut>', self.on_target_focus_out)

        ttk.Button(controls, text='æµè§ˆæ–‡ä»¶', command=self.browse_file, bootstyle='light-outline')\
            .grid(row=0, column=2, padx=5, pady=5)
        self.start_button = ttk.Button(controls, text='å¼€å§‹æ‰«æ', command=self.start_scan, bootstyle='success')
        self.start_button.grid(row=0, column=3, padx=5, pady=5)
        ttk.Button(controls, text='è®¾ç½®', command=self.open_settings, bootstyle='secondary')\
            .grid(row=0, column=4, padx=5, pady=5)
        ttk.Button(controls, text='æ‰“å¼€ç»“æœæ–‡ä»¶å¤¹', command=self.open_results_folder, bootstyle='info')\
            .grid(row=0, column=5, padx=5, pady=5)

        # é€‰é¡¹
        ttk.Label(controls, text='é€‰é¡¹:', style='White.TLabel').grid(row=1, column=0, sticky='w', padx=5, pady=5)
        options = ttk.Frame(controls, style='Transparent.TFrame')
        options.grid(row=1, column=1, columnspan=5, sticky='ew', padx=0, pady=5)
        options.grid_columnconfigure(3, weight=1)

        ttk.Label(options, text='æœç´¢é¡µæ•°:', style='White.TLabel').grid(row=0, column=0, sticky='w')
        self.pages_var = tk.IntVar(value=3)
        ttk.Spinbox(options, from_=1, to=20, textvariable=self.pages_var, width=5)\
            .grid(row=0, column=1, padx=(5, 15), sticky='w')

        ttk.Label(options, text='ä»£ç†:', style='White.TLabel').grid(row=0, column=2, sticky='w')
        self.proxy_var = tk.StringVar(value='')
        ttk.Entry(options, textvariable=self.proxy_var).grid(row=0, column=3, padx=(5, 15), sticky='ew')

        self.show_browser_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(options, text='æ˜¾ç¤ºæµè§ˆå™¨', variable=self.show_browser_var, bootstyle='round-toggle')\
            .grid(row=0, column=4, padx=(0, 5))

        self.verbose_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(options, text='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯', variable=self.verbose_var, bootstyle='round-toggle')\
            .grid(row=0, column=5, padx=(0, 15))

        self.collect_contacts_var = tk.BooleanVar(value=False)
        ttk.Checkbutton(options, text='æ”¶é›†è”ç³»æ–¹å¼', variable=self.collect_contacts_var, bootstyle='round-toggle')\
            .grid(row=0, column=6, padx=(0, 15))

        # æ—¥å¿—
        log_frame = ttk.Labelframe(main_frame, text='æ—¥å¿—è¾“å‡º', padding='10', style='White.TLabelframe')
        log_frame.grid(row=1, column=0, sticky='nsew', pady=(10, 0))
        log_frame.grid_rowconfigure(0, weight=1)
        log_frame.grid_columnconfigure(0, weight=1)

        self.log_text = scrolledtext.ScrolledText(
            log_frame, state='disabled', wrap=tk.WORD, font=('Courier New', 10),
            relief='solid', borderwidth=1, bg='#1C2833', fg='white', insertbackground='white'
        )
        self.log_text.grid(row=0, column=0, sticky='nsew')
        self.log_text.tag_config('INFO', foreground='white')
        self.log_text.tag_config('WARNING', foreground='#F39C12')
        self.log_text.tag_config('ERROR', foreground='#E74C3C')
        self.log_text.tag_config('CRITICAL', foreground='#C0392B', font=('Courier New', 10, 'bold'))
        self.log_text.tag_config('DEBUG', foreground='#7F8C8D')

    # ----- UI å›è°ƒ -----
    def on_target_focus_in(self, _):
        if self.target_entry.get() == self.placeholder_text:
            self.target_entry.delete(0, 'end')
            self.target_entry.config(foreground=self.default_fg_color)

    def on_target_focus_out(self, _):
        if not self.target_entry.get():
            self.target_entry.insert(0, self.placeholder_text)
            self.target_entry.config(foreground=self.placeholder_color)

    def open_settings(self):
        SettingsWindow(self)

    def open_results_folder(self):
        results_path = Path.home() / 'Desktop' / 'sfz_scan' / 'sensitive_files'
        results_path.mkdir(parents=True, exist_ok=True)
        messagebox.showinfo('æç¤º', f'ç»“æœæ–‡ä»¶å¤¹ä½äº:\n{results_path}', parent=self)
        try:
            if sys.platform.startswith('win'):
                os.startfile(results_path)  # type: ignore[attr-defined]
            elif sys.platform == 'darwin':
                subprocess.run(['open', str(results_path)], check=False)
            else:
                subprocess.run(['xdg-open', str(results_path)], check=False)
        except Exception as e:
            messagebox.showerror('é”™è¯¯', f'æ— æ³•æ‰“å¼€æ–‡ä»¶å¤¹: {e}', parent=self)

    def browse_file(self):
        filepath = filedialog.askopenfilename(
            title='é€‰æ‹©åŸŸåæ–‡ä»¶', filetypes=(('Text files', '*.txt'), ('All files', '*.*')), parent=self
        )
        if filepath:
            self.on_target_focus_in(None)
            self.target_var.set(f'file://{filepath}')

    def setup_logging(self):
        self.log_queue: queue.Queue[str] = queue.Queue()
        self.queue_handler = QueueHandler(self.log_queue)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%H:%M:%S')
        self.queue_handler.setFormatter(formatter)
        logger.addHandler(self.queue_handler)

        # æ ¹æ®â€œè¯¦ç»†ä¿¡æ¯â€å¼€å…³åŠ¨æ€è°ƒæ•´æ—¥å¿—çº§åˆ«
        def _refresh_level():
            logger.setLevel(logging.DEBUG if self.verbose_var.get() else logging.INFO)
            self.after(1000, _refresh_level)

        _refresh_level()
        self.after(100, self.poll_log_queue)

    def poll_log_queue(self):
        try:
            while True:
                record = self.log_queue.get(block=False)
                self.display_log(record)
        except queue.Empty:
            pass
        self.after(100, self.poll_log_queue)

    def display_log(self, record: str):
        self.log_text.configure(state='normal')
        level_tag = 'INFO'
        if 'CRITICAL' in record:
            level_tag = 'CRITICAL'
        elif 'ERROR' in record:
            level_tag = 'ERROR'
        elif 'WARNING' in record or 'ğŸš¨' in record or 'ğŸ¯' in record or 'ğŸ”' in record:
            level_tag = 'WARNING'
        self.log_text.insert(tk.END, record + '\n', level_tag)
        self.log_text.configure(state='disabled')
        self.log_text.yview(tk.END)

    def _parse_targets_from_file(self, fp: str) -> list[str]:
        p = fp.replace('file://', '')
        path = Path(p)
        if not path.exists():
            messagebox.showerror('é”™è¯¯', f'æ–‡ä»¶ä¸å­˜åœ¨: {path}', parent=self)
            return []
        domains: list[str] = []
        for line in path.read_text(encoding='utf-8', errors='ignore').splitlines():
            line = line.strip()
            if not line:
                continue
            # å…è®¸ http(s):// å½¢å¼
            if '://' in line:
                netloc = urlparse(line).netloc or line
                domains.append(netloc.split('/')[0])
            else:
                domains.append(line)
        # å»é‡/æ¸…æ´—
        cleaned = []
        for d in domains:
            d = d.replace('http://', '').replace('https://', '').strip('/')
            if d and d not in cleaned:
                cleaned.append(d)
        return cleaned

    def get_targets(self) -> list[str]:
        s = self.target_var.get().strip()
        if not s or s == self.placeholder_text:
            return []
        if s.startswith('file://') or (s.endswith('.txt') and Path(s).exists()):
            return self._parse_targets_from_file(s)
        # å•ä¸ªåŸŸå/URL
        if '://' in s:
            d = urlparse(s).netloc or s
        else:
            d = s
        d = d.replace('http://', '').replace('https://', '').strip('/')
        return [d] if d else []

    def start_scan(self):
        global ssl_failed_domains, domain_reports
        target_domains = self.get_targets()
        if not target_domains:
            messagebox.showwarning('è¾“å…¥é”™è¯¯', 'è¯·è¾“å…¥ä¸€ä¸ªåŸŸåæˆ–é€‰æ‹©ä¸€ä¸ªç›®æ ‡æ–‡ä»¶ã€‚', parent=self)
            return

        # æ¸…çŠ¶æ€
        ssl_failed_domains = set()
        domain_reports = {}

        pages = max(1, int(self.pages_var.get()))
        show_browser = bool(self.show_browser_var.get())
        proxy = self.proxy_var.get().strip()
        collect_contacts = bool(self.collect_contacts_var.get())

        self.start_button.config(text='å–æ¶ˆæ‰«æ', command=self.cancel_scan, bootstyle='danger')
        logger.info(f'ğŸ¯ ç›®æ ‡åŸŸå: {", ".join(target_domains)}')

        # å¯åŠ¨çº¿ç¨‹è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        def _runner():
            self.scan_loop = asyncio.new_event_loop()
            try:
                asyncio.set_event_loop(self.scan_loop)
                self.scan_loop.run_until_complete(
                    async_main_logic(target_domains, pages, show_browser, proxy, collect_contacts)
                )
            except asyncio.CancelledError:
                logger.info('æ‰«æä»»åŠ¡å·²è¢«å–æ¶ˆã€‚')
            except Exception as e:
                logger.error(f'æ‰«æå¼‚å¸¸: {e}')
            finally:
                try:
                    self.scan_loop.close()
                except Exception:
                    pass
                self.scan_loop = None
                self.after(0, self.on_scan_complete)

        self.scan_thread = threading.Thread(target=_runner, daemon=True)
        self.scan_thread.start()

    def cancel_scan(self):
        self.start_button.config(text='æ­£åœ¨å–æ¶ˆ...', state='disabled')
        logger.info('ç”¨æˆ·è¯·æ±‚å–æ¶ˆæ‰«æ...')
        try:
            if self.scan_loop and self.scan_loop.is_running():
                self.scan_loop.call_soon_threadsafe(self.scan_loop.stop)
        finally:
            # UI æ¢å¤åœ¨ on_scan_complete
            pass

    def on_scan_complete(self):
        self.start_button.config(text='å¼€å§‹æ‰«æ', command=self.start_scan, state='normal', bootstyle='success')
        logger.info('==================== æ‰«æä»»åŠ¡å·²ç»“æŸ ====================')

    def show_playwright_install_prompt(self):
        response = messagebox.askyesno('Playwright ä¾èµ–ç¼ºå¤±',
                                       'Playwright Edge æµè§ˆå™¨ä¾èµ–ä¼¼ä¹æœªå®‰è£…ã€‚\næ˜¯å¦è¦å°è¯•è‡ªåŠ¨å®‰è£…ï¼Ÿ',
                                       parent=self)
        if response:
            self.start_button.config(text='æ­£åœ¨å®‰è£…...', state='disabled')
            self.update()
            threading.Thread(target=self.run_playwright_install, daemon=True).start()

    def run_playwright_install(self):
        try:
            logger.info('æ‰§è¡Œ: playwright install msedge')
            subprocess.run([sys.executable, '-m', 'playwright', 'install', 'msedge'],
                           check=True, capture_output=True, text=True, encoding='utf-8')
            logger.info('æ‰§è¡Œ: playwright install-deps msedge')
            subprocess.run([sys.executable, '-m', 'playwright', 'install-deps', 'msedge'],
                           check=True, capture_output=True, text=True, encoding='utf-8')
            logger.info('ä¾èµ–å®‰è£…æˆåŠŸï¼è¯·é‡æ–°å¯åŠ¨ç¨‹åºå¹¶å¼€å§‹æ‰«æã€‚')
            self.after(0, lambda: messagebox.showinfo('æˆåŠŸ', 'ä¾èµ–å®‰è£…æˆåŠŸï¼\nè¯·é‡æ–°å¯åŠ¨ç¨‹åºã€‚'))
            self.after(0, lambda: self.start_button.config(text='å¼€å§‹æ‰«æ', state='normal'))
        except subprocess.CalledProcessError as e:
            logger.error(f'è‡ªåŠ¨å®‰è£…å¤±è´¥: {e}\nOutput: {e.stdout}\nError: {e.stderr}')
            self.after(0, lambda: messagebox.showerror('å®‰è£…å¤±è´¥', 'è‡ªåŠ¨å®‰è£…å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æˆ–æ‰‹åŠ¨æ‰§è¡Œå®‰è£…å‘½ä»¤ã€‚'))


# --------------------------- å…¥å£ ---------------------------

if __name__ == '__main__':
    try:
        app = App()
        globals()['app_instance'] = app
        app.mainloop()
    except KeyboardInterrupt:
        logger.info('\nç”¨æˆ·æ‰‹åŠ¨é€€å‡ºç¨‹åºã€‚')
